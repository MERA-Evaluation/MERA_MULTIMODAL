# RuSLUn


## Описание задачи

RuSLUn (Russian Spoken Language UNderstanding dataset) — это датасет для задачи понимания устной речи на русском языке, построенный по принципу англоязычного датасета [SLURP](https://arxiv.org/pdf/2011.13205) и мультиязычного [xSID](https://aclanthology.org/2021.naacl-main.197.pdf), но с учетом культурных и языковых особенностей России. Он предназначен для оценки моделей, которые напрямую преобразуют аудиозаписи в семантическое представление, включая определение намерений пользователя (intent detection) и извлечение слотов (slot filling). ruSLUn включает разнообразные голосовые команды и запросы, характерные для российских пользователей и реалий. Особенность датасета заключается в его локализации: помимо русского языка, учтены типичные сценарии использования, лексика и контекст, что делает его релевантным для разработки голосовых ассистентов в русскоязычных сервисах.

Тестируемые навыки моделей: Speech recognition, Problem decomposition, Common everyday knowledge

Авторы: Заряна Дамашова, Екатерина Артемова, Ильсеяр Алимова


## Мотивация

Традиционно задача понимания устной речи (SLU) решается поэтапно: сначала аудиозапись преобразуется в текст с помощью автоматического распознавания речи (ASR), а затем из текста извлекается необходимая информация с помощью технологий понимания естественного языка (NLU). Однако такой модульный подход подвержен накоплению ошибок из-за неточностей распознавания речи, а также требует использования двух отдельных моделей или двух последовательных этапов обработки, что замедляет работу системы. Датасет ruSLUn предназначен для оценки аудиомоделей, способных напрямую, в формате end-to-end, понимать и интерпретировать смысл аудиоданных без промежуточного этапа ASR. Кроме того, ruSLUn — первый датасет для русского языка, в котором аудиозаписи напрямую сопоставлены с соответствующими выделенными классами и слотами, что позволяет полноценно исследовать задачи понимания речи в end-to-end формате с учётом культурных и языковых особенностей российских пользователей.


## Описание датасета

### Поля данных

Каждый вопрос в датасете содержит следующие поля:

- `instruction` [str] — Промпт-инструкция для модели, содержащая шаблон для вставки элементов вопроса.
- `inputs` — Вводные данные, формирующие задание для модели.
    - `audio` [str] — Путь к файлу с аудио, к которому относится вопрос.
    - `question` [str] — Текст вопроса.
    - `annotation` [str] — Список доступных намерений и слотов.
- `outputs` — Правильный ответ на вопрос.
    - `intent` [str] — Намерение пользователя;
    - `slots` [list] — Список слотов в формате json, где ключом является тип слота, а значением — выделенный слот.
- `meta` — Метаданные, относящиеся к тестовому примеру, но не используемые в вопросе (скрытые от тестируемой модели).
    - `id` [int] — Номер-идентификатор вопроса в датасете.
    - `audio` — Метаданные, относящиеся к аудио.
        - `type` [str] — Тип аудио — согласно классификации аудио для датасетов MERA.
    - `speaker` [str] — id_пол_возраст


### Пример данных

```json
{
    "instruction": "В датасете к задаче идёт такой промпт:\n\nНе обязательно все слоты присутствуют в запросе.\nАудиофайл: <audio>\nВопрос:\n{question}\n\nПрошу решить задачу на основе вышеизложенного и кратко сформулировать ответ.\n\n{annotation}",
    "inputs": {
        "audio": "samples/audio_2.wav",
        "question": "Внимательно послушай <audio> с запросом пользователя, классифицируй к какому намерению (intent) относится запрос пользователя и выдели соответствующие данному намерению все возможные слоты (slots). Слова в слотах должны быть в той же морфологической форме, что и в аудио, цифры должны быть записаны текстом.",
        "annotation": "Список доступных намерений с соответствующими слотами в формате намерение: [список слотов].\nBookRestaurant: [cuisine, datetime, facility, location, party_size_description, party_size_number, restaurant_name, restaurant_type, served_dish, sort]\nSearchScreeningEvent: [datetime, location, movie_name, movie_type, object_location_type, object_type]\nSearchCreativeWork: [object_name, object_type]\nAddToPlaylist: [artist, entity_name, music_item, playlist, reference]\nRateBook: [best_rating, object_name, object_part_of_series_type, object_select, object_type, rating_unit, rating_value]\nPlayMusic: [album, artist, datetime, genre, music_item, playlist, service, sort, track]\nweather/find: [condition_description, condition_temperature, datetime, location, weather/attribute]\nalarm/cancel_alarm: [datetime, reference]\nreminder/set_reminder: [datetime, recurring_datetime, reminder/todo]\nreminder/cancel_reminder: [datetime, reference, reminder/todo]\nreminder/show_reminders: [datetime, reference, reminder/todo]\nalarm/set_alarm: [datetime, recurring_datetime, reference, reminder/todo]\nalarm/show_alarms: [datetime, reference]\nalarm/modify_alarm: [datetime]\nalarm/snooze_alarm: [reference]\nalarm/time_left_on_alarm: []\n\nОтвет должен быть в формате валидного json, по схеме: {\"intent\": \"выбранный из списка intent\", \"slots\": [{\"тип слота\": \"значение слота\"}, {\"тип слота\": \"значение слота\"}, {\"тип слота\": \"значение слота\"}]}. Выведи только валидный JSON без форматирования, комментариев и обратных кавычек."
    },
    "outputs": {
        "intent": "RateBook",
        "slots": [
            {
                "object_name": "доктор живаго"
            },
            {
                "rating_value": "три"
            },
            {
                "best_rating": "шести"
            },
            {
                "rating_unit": "звезд"
            }
        ]
    },
    "meta": {
        "id": 2,
        "audio": {
            "type": "real"
        },
        "speaker": "7_female_33"
    }
}
```


### Создание датасета

Датасет был создан в два этапа: сначала формировались текстовые запросы с разметкой интентов и слотов, затем эти запросы были озвучены.
 В основе разметки лежит схема из кросс-языкового датасета [xSID](https://aclanthology.org/2021.naacl-main.197.pdf), который включает 16 типов интентов и 33 типа слотов. На первом этапе были вручную переведены валидационные и тестовые данные xSID на русский язык одним из авторов датасета. Затем тексты были адаптированы под русскоязычный контекст: локации, имена исполнителей, названия фильмов, песен и ресторанов заменялись на наиболее популярные и узнаваемые для отечественной аудитории аналоги. Замены подбирались вручную и случайным образом из списка наиболее распространённых вариантов.
Текстовые данные прошли постобработку, в которую входило: удаление знаков препинания, преобразование всех цифр в текстовый вид, приведение текста к нижнему регистру.
После завершения работы с текстовыми данными была выполнена озвучка запросов из датасета. Для записи аудио привлекались 7 спикеров разного возраста (5 женщин и 2 мужчины), не являющихся профессиональными дикторами. Перед началом записи всем участникам были выданы инструкции: находиться в тихой обстановке, говорить естественным голосом и записывать каждое предложение в отдельный аудиофайл. Озвучка проходила в домашних условиях на обычный диктофон, поэтому в аудиоданных естественным образом присутствуют фоновые шумы (например, вздохи, шарканье и др.).
Финальный датасет прошел проверку модератором: вручную контролировалось соответствие аудиозаписей текстовым данным, а также корректность разметки интентов и слотов.


## Оценка

### Метрики

Для агрегированной оценки ответов моделей используются следующие метрики:

- `Intent Exact Match`: Метрика Intent Exact Match вычисляет среднее по оценкам всех примеров: оценка = 1, если предсказанный intent точно совпадает с правильным, и 0 в противном случае.
- `Slots F1`: Макро-усреднённая F1 по всем примерам для слотов. Для каждого примера вычисляют precision (доля выделенных слотов, оказавшихся верными) и recall (доля правильных слотов, которые были выделены). Слот считается выделенным верно, если совпали его тип и значение; по precision и recall вычисляется F1 для одного примера.


### Human baseline

Human baseline — это оценка усредненных ответов людей на вопросы бенчмарка. Оценка проводится по тем же метрикам, что и для моделей.

Для всех вопросов датасета были получены ответы разметчиков на crowd-source платформе с перекрытием 5. Ответы в свободной форме были нормализованы (регистр, пробелы) для сравнения с эталоном. Агрегированным ответом считался тот, который был выбран большинством (majority vote).

Результаты оценки:

- Intent Exact Match – 0.91
- Slots F1 – 0.30
