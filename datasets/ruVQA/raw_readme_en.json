{
    "Task description": "ruVQA is a public question-answering dataset in Russian for two types of images: real photos and abstract illustrations. The questions are divided into 1) simple and 2) complex, categorized by the most frequent types: binary, comparative, how many, where, how, which, what, who. Simple questions require only image-based perception, while complex ones require a step of reasoning. All images in the dataset are classic, from public sources, including real photos and cartoonish abstract images. The dataset is public and serves as a foundational VQA (Visual Question Answering) dataset for the Russian language.",
    "Motivation": "The dataset addresses the classic foundational Visual Question Answering (VQA) task, similar to English datasets [VQA](https://visualqa.org/download.html). For Russian, there is no publicly available baseline VQA dataset to evaluate image-text models. This dataset is designed to test the basic capabilities of models to distinguish objects in various types of images, understand different question types, and generate short answers based on the image. The questions cover key abilities: understanding objects in the image (Fine-grained Perception, single instance), overall image perception (Coarse perception), common sense, and general knowledge. Since the images are sourced from public datasets (COCO dataset, English VQA v2), this should be considered as limitation when interpreting the evaluation. There is a possibility of indirect data leakage through the images in model training data.",
    "Dataset creation": "The dataset was created using images from the English VQA v2 dataset (which includes data from the COCO dataset). Using the ABC Elementary platform, annotators generated questions and answers for the images from scratch, for each image 3 questions were created and each image was annotated by three annotators. The resulting data was then aggregated and filtered both automatically (to remove long answers, typos, and formatting issues) and manually. The binary question data is balanced across classes.",
    "Human baseline": "",
    "Contributors": ""
}