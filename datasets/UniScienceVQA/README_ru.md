# UniScienceVQA


## Описание задачи

UniScienceVQA — мультимодальный датасет, состоящий из заданий на проверку экспертных знаний в различных областях науки (фундаментальные, социальные и прикладные науки, культуроведение, бизнес, здоровье и медицина), задания представлены в виде изображений и вопросов с аннотацией к ним. Задания делятся на три группу по варианту ответ: 1) с коротким ответом; 2) с вариантами ответов; 3) с вариантами ответов, на которые нет верного ответа.

Тестируемые навыки моделей: Expert domain knowledge, Scheme recognition, Text recognition (OCR), Static counting, Problem decomposition, Comparative reasoning, Physical property understanding, Mathematical reasoning

Авторы: Александр Капитанов, Петр Суровцев


## Мотивация

Датасет представляет собой открытую базу задач для проверки способностей модели понимать элементы изображения из университетской программы и профессиональной сферы. Особенностью данного задания является проверка моделей давать короткий и точный ответ, а так же находить правильный ответ из нескольких варинантов ответов. 

Датасет предназначается для моделей Vision + Text, которые умеют не только понимать, что изображено, но и обладают экспертными знаниями университетской программы. 

Данный датасет не проверяет ход решения и не требует вывести рассуждения для задачи — ответом на задачу является короткий ответ числом / формулой. Аннотация служит инструкцией для записи однозначного короткого ответа на задачу в требуемой пользователем форме. Поэтому в качестве метрики используется Accuracy.


## Описание датасета

### Поля данных

Каждый вопрос в датасете содержит следующие поля:

- `instruction` [str] — Промпт-инструкция для модели, содержащая шаблон для вставки элементов вопроса.
- `inputs` — Вводные данные, формирующие задание для модели.
    - `image` [str] — Путь к файлу с изображением, к которому относится вопрос.
    - `question` [str] — Текст вопроса.
    - `annotation` [str] — формат выдаваемого ответа;
- `outputs` [str] — Правильный ответ на вопрос.
- `meta` — Метаданные, относящиеся к тестовому примеру, но не используемые в вопросе (скрытые от тестируемой модели).
    - `id` [int] — Номер-идентификатор вопроса в датасете.
    - `categories` — Категории признаков, характеризующих тестовый пример.
        - `subdomain` [str] — Поддомен задания.
        - `type_answer` [str] — Варинат ответа: короткий ответ или выбор правильного ответа.
    - `image` — Метаданные, относящиеся к изображению.
        - `source` [str] — Информация о происхождении изображения — согласно классификации изображений для датасетов MERA.
        - `type` [str] — Тип изображения — согласно классификации изображений для датасетов MERA.
        - `content` [str] — Содержание изображения — согласно классификации изображений для датасетов MERA.


### Пример данных

```json
{
    "instruction": "Ознакомьтесь с изображением <image> и дайте ответ на вопрос. {question} {annotation}\nОтвет:",
    "inputs": {
        "image": "samples/image01633.jpg",
        "question": "Какой порядок группы автоморфизмов изображенного графа?",
        "annotation": "В ответе напишите только число."
    },
    "outputs": "72",
    "meta": {
        "id": 1633,
        "categories": {
            "subdomain": "Computer science and Programming",
            "type_answer": "short answer"
        },
        "image": {
            "source": "photo",
            "type": "visual",
            "content": "riddle"
        }
    }
}
```


### Создание датасета

Датасет состоит из 25 поддоменов и для сбора данных по каждому поддомену привлекалась группа экспертов с углубленными знаниями в этой области. Изображения для датасета были нарисованы или сфотографированы экспертами. Создание датасета включала два этапа: 1) создание изображение, вопроса и ответа; 2) проверка созданных данных. Аннотация, которая содержит формат для однозначной записи ответа на задачу, была вручную добавлена в соответствии с ответом. К каждой задаче в инструкции добавлен универсальный текст: «Прочитайте вопрос и решите задачу задачу.». В результате на каждый поддомен было собрано 200-400 заданий.


## Оценка

### Метрики

Для агрегированной оценки ответов моделей используются следующие метрики:

- `Exact match`: Метрика Exact match вычисляет среднее по оценкам всех обработанных вопросов, где оценка имеет значение 1, если предсказанная строка точно совпадает с правильным ответом, и 0 в остальных случаях.


### Human baseline

Human baseline — это оценка усредненных ответов людей на вопросы бенчмарка. Оценка проводится по тем же метрикам, что и для моделей.

Для всех вопросов датасета были получены ответы разметчиков на crowd-source платформе с перекрытием 5. Ответы в свободной форме были нормализованы (регистр, пробелы) для сравнения с эталоном. Агрегированным ответом считался тот, который был выбран большинством (majority vote).

Результаты оценки:

- Exact match – 0.13
