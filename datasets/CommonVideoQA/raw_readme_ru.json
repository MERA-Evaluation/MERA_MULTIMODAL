{
    "Описание задачи": "CommonVideoQA – вопросно-ответный публичный датасет на русском языке для оценки видео-текстовых моделей (Video-LLMs), содержащий вопросы к видеороликам. Комплексно проверяет следующие навыки: общее понимание видео и его деталей, наличие общих и доменных знаний, способность определять точный порядок действий в видео и восстанавливать полную последовательность, возможность подсчета объектов и действий во времени, а также способность связывать действия с соответствующими временными границами в видео. На основе переданных видео и вопроса необходимо выбрать единственно верный вариант ответа из четырех предложенных. Для правильного ответа не требуется прослушивание аудиоряда. Все видеоролики взяты из открытых публичных источников.",
    "Мотивация": "Большинство опубликованных бенчмарков в области понимания видео сфокусированы на английском языке, и на текущий момент нет ни одного бенчмарка на русском в открытом доступе. Датасет CommonVideoQA призван закрыть этот пробел: он позволяет оценить, насколько эффективно видеомодели способны отвечать на вопросы, требующие понимания видео (задача VideoQA). Данный датасет покрывает проверку как базовых, так и продвинутых способностей моделей в общем понимании видео и его деталей (за исключением восприятия аудиодорожки из видео), понимании вопросов различного типа и возможности выбрать правильный ответ из предложенных вариантов.\n\nВ категории \"общее описание\" требуется ответить на вопрос об основном действии в видео или объекте на главном плане. Вопросы из категории \"детали и атрибуты\" спрашивают о специфике деталей, об объектах на второстепенном плане. В \"общих и доменных знаниях\" содержатся вопросы, требующие как классических повседневных знаний, так и знаний некоторой прикладной области (\"В каком порядке должно готовиться представленное блюдо?\"). К категории \"последовательности действий\" относятся вопросы, проверяющие понимание действий, происходящих на видео, их взаимного следования, а также проверяющие умение восстанавливать эту последовательность. К \"подсчёту\" относятся вопросы, определяющие способность подсчитывать различные объекты, количество повторений действия, разнесенных во времени, и умение выполнять простые арифметические операции с найденным количеством. В категории \"временной интервал\" проверяется способность связывать действия из видео с временными границами (таймкодами видео), в которые происходят эти действия. Таким образом, датасет проверяет ключевые для видеодомена навыки моделей.\n\nНабор данных содержит видеосюжеты, охватывающие следующие области: «кухни» (включая повседневную домашнюю деятельность), «спорт» (тренировочные процессы и соревнования), «флора и фауна» (изображение ландшафтов, дикой природы и растений), «инструменты» (применение различных приспособлений и вспомогательных предметов) и «хобби» (широкий спектр досуговых занятий). Примеры в датасете не требуют понимания аудиоряда видео, сами видео взяты из открытых источников (EPIC-KITCHENS), это необходимо учитывать при интерпретации оценки.",
    "Создание датасета": "Для создания датасета использовались видеоролики из датасетов EPIC-KITCHENS-100 и Kinetics-600. С помощью платформы TagMe разметчики составляли вопросы и варианты ответов для каждой категории. В каждом примере только один правильный вариант ответа, что исключает неоднозначность. Проведены два этапа валидации разметки аннотаторами с перекрытием 3 и последующая агрегация результатов. Примеры, где не все разметчики дали одинаковый ответ, прошли дополнительный этап валидации и редактуры. В конце была выполнена постобработка для исправления опечаток. Правильные варианты ответов сбалансированы по классам.",
    "Авторы": "Вильдан Сабуров",
    "Human baseline": "Для всех вопросов датасета были получены ответы разметчиков на crowd-source платформе с перекрытием 5. Ответы в свободной форме были нормализованы (регистр, пробелы) для сравнения с эталоном. Агрегированным ответом считался тот, который был выбран большинством (majority vote)."
}