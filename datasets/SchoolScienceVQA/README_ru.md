# SchoolScienceVQA


## Описание задачи

SchoolScienceVQA — русскоязычный мультимодальный датасет, созданный по методологии [ScienceQA](https://scienceqa.github.io/index.html#home) и адаптированный под школьную программу и культурный контекст России. Он содержит вопросы с выбором ответа из нескольких вариантов по дисциплинам: физика, биология, химия, экономика, история и естествознание. Каждый вопрос сопровождается изображением, текстовым контекстом и объяснением, что позволяет оценивать рассуждения модели.

Тестируемые навыки моделей: Expert domain knowledge, Scheme recognition, Text recognition (OCR), Static counting, Problem decomposition, Comparative reasoning, Physical property understanding, Mathematical reasoning

Авторы: Мария Тихонова, Юлия Лях


## Мотивация

SchoolScienceVQA предназначен для оценки AI-моделей в задачах, требующих одновременной обработки текстовой и визуальной информации.

- **Оценка моделей**: Подходит для моделей мультимодального типа (vision-language). Не применим к моделям без обработки изображений.

- **Целевая аудитория**: Исследователи и разработчики в области мультимодальных моделей, особенно в образовательных и научных приложениях. Преподаватели могут использовать датасет для оценки качества имитации понимания научных задач.

- **Содержание вопросов**: Вопросы имитируют задачи из образовательной практики и требуют подлинного мультимодального анализа.


## Описание датасета

### Поля данных

Каждый вопрос в датасете содержит следующие поля:

- `instruction` [str] — Промпт-инструкция для модели, содержащая шаблон для вставки элементов вопроса.
- `inputs` — Вводные данные, формирующие задание для модели.
    - `image` [str] — Путь к файлу с изображением, к которому относится вопрос.
    - `context` [str] — Дополнительная информация, которая вместе с картинкой используется для ответа на вопрос.
    - `question` [str] — Текст вопроса.
    - `option_a` [str] — Вариант ответа A.
    - `option_b` [str] — Вариант ответа B.
    - `option_c` [str] — Вариант ответа C.
    - `option_d` [str] — Вариант ответа D.
- `outputs` [str] — Правильный ответ на вопрос.
- `meta` — Метаданные, относящиеся к тестовому примеру, но не используемые в вопросе (скрытые от тестируемой модели).
    - `id` [int] — Номер-идентификатор вопроса в датасете.
    - `categories` — Категории признаков, характеризующих тестовый пример.
        - `domain` [str] — Научный домен, к которому относится тестовый пример.
        - `question_difficulty` [int] — Сложность вопроса по шкале от 1 до 3.
    - `image` — Метаданные, относящиеся к изображению.
        - `type` [list] — Тип изображения — согласно классификации изображений для датасетов MERA.
        - `source` [list] — Информация о происхождении изображения — согласно классификации изображений для датасетов MERA.


### Пример данных

```json
{
    "instruction": "Дано: вопрос с четырьмя вариантами ответа, изображение и, возможно, пояснение к нему. По имеющейся информации ответь на вопрос. В качестве ответа напиши букву правильного ответа без дополнительных пояснений (A, B, C или D).\nИзображение: <image>.\nПояснение: {context}\nВопрос: {question}\nA. {option_a}\nB. {option_b}\nC. {option_c}\nD. {option_d}\nОтвет: ",
    "inputs": {
        "image": "samples/image0760.jpg",
        "context": "",
        "question": "На каком из перечисленных геологических образований вероятность сохранения изображенного на фото покрова на вершинах в течение всего года самая низкая?",
        "option_a": "Аконкагуа, Аргентина",
        "option_b": "Монблан, Франция",
        "option_c": "Килиманджаро, Танзания",
        "option_d": "Денали, США"
    },
    "outputs": "C",
    "meta": {
        "id": 760,
        "image": {
            "type": [
                "visual"
            ],
            "source": [
                "photo"
            ]
        },
        "categories": {
            "domain": "earth_science",
            "question_difficulty": 3
        }
    }
}
```


### Создание датасета

SchoolScienceVQA создан с нуля по методологической основе ScienceQA с адаптацией под российскую школьную программу и культурные реалии.

Аннотацию выполняли эксперты из соответствующих областей. Все изображения созданы специально для датасета: фотографии, иллюстрации, схемы, графика и генерация с помощью нейросетей. Изображения не используются в других наборах данных. Метаданные включают информацию о способе генерации для обеспечения прозрачности и предотвращения смещений.


## Оценка

### Метрики

Для агрегированной оценки ответов моделей используются следующие метрики:

- `Exact match`: Метрика Exact match вычисляет среднее по оценкам всех обработанных вопросов, где оценка имеет значение 1, если предсказанная строка точно совпадает с правильным ответом, и 0 в остальных случаях.


### Human baseline

Human baseline — это оценка усредненных ответов людей на вопросы бенчмарка. Оценка проводится по тем же метрикам, что и для моделей.

Задания датасета было предложено решить группе людей без подготовки (перекрытие 5) и группе экспертов (перекрытие 3). Агрегированным ответом считался тот, который был выбран большинством (majority vote).

Результаты оценки:

- Exact match – 0.48

- Exact match (expert) – 0.82
