{
    "dataset_name": "ruCommonVQA",
    "license": "[CC-BY-4.0](https://choosealicense.com/licenses/cc-by-4.0/)",
    "dataset_size": 3015,
    "description": "ruVQA is a public question-answering dataset in Russian for two types of images: real photos and abstract illustrations. The questions are divided into 1) simple and 2) complex, categorized by the most frequent types: binary, comparative, how many, where, how, which, what, who, and mix.",
    "modalities": [
        "image",
        "text"
    ],
    "skills": [
        "Scene understanding",
        "Physical property understanding",
        "Object function understanding",
        "Identity & emotion understanding",
        "Static counting",
        "Common everyday knowledge",
        "Spatial object relationship",
        "Object-object interaction",
        "Human-object interaction",
        "Human-human interaction",
        "Object localization",
        "Object recognition",
        "Living things motion recognition",
        "Object motion recognition"
    ],
    "domains": [],
    "universal_domains": [],
    "synt_source_models": [],
    "data_example": {
        "instruction": "Внимательно посмотрите на картинку <image>.\nОтветьте кратко на вопрос. В качестве ответа напишите слово в той же форме, как спрашивается в вопросе, без дополнительных рассуждений, либо цифру, если ответом является число.\nВопрос:{question}\nОтвет:",
        "inputs": {
            "image": "samples/image0001.jpg",
            "question": "На фото есть люди?"
        },
        "outputs": "Да",
        "meta": {
            "id": 123,
            "categories": {
                "question_type": "binary"
            },
            "image": {
                "source": [
                    "photo"
                ]
            },
            "complexity": "simple"
        }
    },
    "data_field_descriptions": {
        "instruction": {
            "ru": "default",
            "en": "default"
        },
        "inputs": {
            "image": {
                "ru": "default",
                "en": "default"
            },
            "question": {
                "ru": "default",
                "en": "default"
            }
        },
        "outputs": {
            "ru": "default",
            "en": "default"
        },
        "meta": {
            "id": {
                "ru": "default",
                "en": "default"
            },
            "categories": {
                "question_type": {
                    "ru": "типы вопросов: бинарный, сравнительный, сколько, где, как, какой, что, кто",
                    "en": "question types: compare, how much, what, which, where, who, how, binary"
                }
            },
            "image": {
                "source": {
                    "ru": "источник изображений: фото из COCO или абстрактная картинка",
                    "en": "source of the image: photo or abstract"
                }
            },
            "complexity": {
                "ru": "Сложность вопроса: простая или сложная",
                "en": "Complexity of the question: complex / simple"
            }
        }
    },
    "task_type": "short",
    "task_description": "Задача на понимание содержания изображения с бинарными (да/нет), сравнительными, количественными (сколько), пространственными (где), процедурными (как), описательными (какой), предметными (кто/что) и смешанными типами вопросов на основе данных изображений.",
    "prompts": {
        "task_context": {
            "default": [
                "Задаваемый вопрос прямо связан с содержанием изображения, а также различными отношениями между элементами данного изображения."
            ]
        },
        "answer_format": {
            "none": [
                ""
            ],
            "formal_request": [
                "{{ answer_format_formal_request(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_request": [
                "{{ answer_format_informal_request(get_ruvqa_public_task_type(sample)) }}"
            ],
            "impersonal_request": [
                "{{ answer_format_impersonal_request(get_ruvqa_public_task_type(sample)) }}"
            ],
            "formal_wish": [
                "{{ answer_format_formal_wish(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_order": [
                "{{ answer_format_informal_order(get_ruvqa_public_task_type(sample)) }}"
            ],
            "impersonal_order": [
                "{{ answer_format_impersonal_order(get_ruvqa_public_task_type(sample)) }}"
            ],
            "impersonal_fact": [
                "{{ answer_format_impersonal_fact(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_manipulation": [
                "{{ answer_format_informal_manipulation(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_technical": [
                "{{ answer_format_informal_technical(get_ruvqa_public_task_type(sample)) }}"
            ]
        },
        "processing_data": {
            "none": [
                ""
            ],
            "formal_request": [
                "{{ processing_data_formal_request(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_request": [
                "{{ processing_data_informal_request(get_ruvqa_public_task_type(sample)) }}"
            ],
            "impersonal_request": [
                "{{ processing_data_impersonal_request(get_ruvqa_public_task_type(sample)) }}"
            ],
            "formal_wish": [
                "{{ processing_data_formal_wish(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_order": [
                "{{ processing_data_informal_order(get_ruvqa_public_task_type(sample)) }}"
            ],
            "impersonal_order": [
                "{{ processing_data_impersonal_order(get_ruvqa_public_task_type(sample)) }}"
            ],
            "impersonal_fact": [
                "{{ processing_data_impersonal_fact(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_manipulation": [
                "{{ processing_data_informal_manipulation(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_technical": [
                "{{ processing_data_informal_technical(get_ruvqa_public_task_type(sample)) }}"
            ]
        },
        "solution_motivation": {
            "none": [
                ""
            ],
            "formal_request": [
                "{{ solution_motivation_formal_request(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_request": [
                "{{ solution_motivation_informal_request(get_ruvqa_public_task_type(sample)) }}"
            ],
            "impersonal_request": [
                "{{ solution_motivation_impersonal_request(get_ruvqa_public_task_type(sample)) }}"
            ],
            "formal_wish": [
                "{{ solution_motivation_formal_wish(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_order": [
                "{{ solution_motivation_informal_order(get_ruvqa_public_task_type(sample)) }}"
            ],
            "impersonal_order": [
                "{{ solution_motivation_impersonal_order(get_ruvqa_public_task_type(sample)) }}"
            ],
            "impersonal_fact": [
                "{{ solution_motivation_impersonal_fact(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_manipulation": [
                "{{ solution_motivation_informal_manipulation(get_ruvqa_public_task_type(sample)) }}"
            ],
            "informal_technical": [
                "{{ solution_motivation_informal_technical(get_ruvqa_public_task_type(sample)) }}"
            ]
        }
    },
    "exclude_fields": {},
    "metrics": {
        "Exact match": {
            "ru": "default",
            "en": "default"
        }
    },
    "human_benchmark": {
        "Exact match": 0.8180
    }
}