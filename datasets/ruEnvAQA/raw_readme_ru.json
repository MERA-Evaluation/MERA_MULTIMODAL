{
    "Описание задачи": "{meta[\"dataset_name\"]} – датасет вопросов с множественным и бинарным выбором ответа на русском языке. Вопросы связаны с анализом музыки и невербальных аудиосигналов. Датасет составлен на основе вопросов из англоязычных датасетов [Clotho-AQA](https://arxiv.org/abs/2204.09634) и [MUSIC-AVQA](https://arxiv.org/abs/2203.14072v2). Вопросы переведены на русский язык и частично изменены, тогда как аудиозаписи использованы в исходном виде (с обрезкой по длине).\n\nДатасет включает вопросы 8 типов:\n\n- Оригинальные классы вопросов из MUSIC-AVQA (около половины вопросов на экспертные знания о звучании редких инструментов, остальные — на общие знания):\n    - `Music instrument counting` — \"Сколько музыкальных инструментов звучат на записи?\";\n    - `Single music instrument detection` — \"Звучит ли на записи <инструмент_X>?\";\n    - `Double music instrument detection` — \"Верно ли, что на записи звучит и <инструмент_X>, и <инструмент_Y>?\";\n    - `Music instrument comparison (louder)` — \"Верно ли, что на записи <инструмент_X> играет громче, чем <инструмент_Y>?\";\n    - `Music instrument comparison (longer)` — \"Верно ли, что на записи <инструмент_X> играет более продолжительное время, чем <инструмент_Y>?\";\n\n- Классы, присвоенные при редактуре вопросов CLOTHO-AQA (вопросы на общие знания):\n    - `Audio scene classification` — понимание аудиосцены в целом, логический вывод из множества деталей (определение, в каком месте или обстоятельствах записано аудио);\n    - `Audio captioning` — вопросы на понимание отдельных деталей аудиофрагмента, порядка и количества событий;\n    - `Sound QA with reasoning` — вопросы на понимание аудио с простым ризонингом, требующие не только восприятия деталей из аудиосигнала, но и шага логического рассуждения.",
    "Мотивация": "Методология оценки больших аудио-языковых моделей (large audio language models, LALMs), как и сами такие модели, — относительно новое явление. По сравнению с vision-language доменом, существует меньше крупных бенчмарков, объединяющих разнообразные задачи для оценки навыков LALMs. Примерами таких бенчмарков являются [AIR-Bench (02.2024)](https://arxiv.org/abs/2402.07729), [AudioBench (06.2024)](https://arxiv.org/abs/2406.16020) и [MMAU (10.2024)](https://arxiv.org/abs/2410.19168v1). За основу классификации задач на понимание аудио можно принять разделение задач на анализ речи, невербальных сигналов и музыки.\n\nДанный датасет тестирует способности LALMs воспринимать и анализировать невербальные сигналы и музыку, отвечая на вопросы на русском языке к аудио, на которых записано исполнение музыкальных композиций и аудиосцены из разнообразных жизненных ситуаций. В тесты включены вопросы трех категорий:\n- **Вопросы на буквальное восприятие аудиособытий** (Audio captioning и вопросы про музыку) тестируют умение моделей сопоставлять запечатленные в аудио последовательности событий, их количество и длительность с их текстовым описанием. Например, \"Сколько раз мяч ударился о пол?\" или \"Звучит ли на записи скрипка?\".\n- **Вопросы на классификацию аудиосцен** (Audio scene classification) проверяют способность моделей проводить индуктивные рассуждения, а именно определять место и обстоятельства записи аудио по деталям событий. Например, если на записи слышны самолеты и объявления диктора, она, вероятно, сделана в аэропорту.\n- **Вопросы с дополнительным рассуждением** (Sound QA with reasoning) помимо базового восприятия аудиоинформации требуют дополнительных логических операций с общими знаниями о мире для вывода ответа. Например, на аудио мяукает кошка, вопрос: \"Как обычно передвигаются эти животные?\".",
    "Создание датасета": "Датасет составлен из аудиофайлов и вопросов в равных пропорциях из двух англоязычных датасетов, покрывающих по отдельности домен музыки и невербальных сигналов. Вопросы на понимание речи в датасет не включены.\n\n\n### Вопросы из датасета Clotho-AQA\n\nДатасет [Clotho-AQA](https://arxiv.org/abs/2204.09634) содержит вопросы к аудио с невербальными сигналами с минорными вкраплениями речи, вопросы касаются только невербальных сигналов и лишь изредка внешних характеристик речи, таких как громкость или пол говорящего.\n\nОригинальные вопросы из test split были переведены в multiple-choice формат, для этого в дополнение к единственному правильному ответу из исходного датасета на каждый вопрос были сгенерированы по 3 дистрактора (неправильных варианта ответа) моделью [Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct) на английском языке.\n\nВопросы, правильные ответы и дистракторы были переведены на русский язык с помощью [DeepL API](https://www.deepl.com/products/api). Вопросы переводились единой последовательностью вместе с ответами, чтобы снизить влияние синонимии при переводе.\n\nПолученные автопереводом вопросы и варианты ответов с соответствующими аудиофайлами были проверены профессиональными редакторами (без перекрытия в разметке) с учетом оригинальных формулировок вопросов. В случае, если исходный вопрос не подходил для перевода, редактор подбирал новый вопрос к аудио, определял правильный ответ и дистракторы. Также редактор выбирал подходящий тип вопроса: Audio scene classification, Audio captioning или Sound QA with reasoning.\n\n\n### Вопросы из MUSIC-AVQA\n\nДатасет [MUSIC-AVQA](https://gewu-lab.github.io/MUSIC-AVQA/) состоит из видеозаписей исполнения музыкальных произведений и трех групп вопросов к ним:\n- вопросы к звуковой части видео, не требующие анализа визуального компонента;\n- вопросы к визуальному ряду, не требующие понимания сопутствующего аудио;\n- вопросы к аудиовизуальному ряду, относящиеся одновременно к звуковой и визуальной частям видео.\n\nДля датасета {meta[\"dataset_name\"]} были выбраны вопросы, относящиеся только к аудио (только test split). Из каждого видео был извлечен звуковой компонент и использован как самостоятельный wav-файл.\n\nВыбранные вопросы составлены по шаблонам, которые заполняются названиями музыкальных инструментов (22 разных инструмента):\n- \"Сколько музыкальных инструментов звучат на записи?\";\n- \"Звучит ли на записи <инструмент_X>?\";\n- \"Верно ли, что на записи звучит и <инструмент_X>, и <инструмент_Y>?\";\n- \"Верно ли, что на записи <инструмент_X> играет громче, чем <инструмент_Y>?\";\n- \"Верно ли, что на записи <инструмент_X> играет более продолжительное время, чем <инструмент_Y>?\";\n\nШаблоны и названия инструментов, а также шаблонные ответы были переведены вручную. Вопросы были отобраны так, чтобы сбалансировать типы вопросов и ответы, а также упоминаемые в вопросах музыкальные инструменты.\n\nВопросы исходного датасета были приведены к формату бинарных вопросов. Для вопросов «Сколько музыкальных инструментов звучат на записи?» были составлены варианты ответа \"один\" и \"несколько\", остальные вопросы — сведены к выбору \"да\"/\"нет\". Таким образом, в получившемся датасете сбалансированы вопросы с двумя и четырьмя вариантами ответов.\n\n\n### Валидация вопросов и обработка аудио\n\nПредварительно отобранные вопросы из двух датасетов проходили валидацию краудсорс-разметчиками с перекрытием 3. Разметчикам было предложено аудио, вопрос и варианты ответа, задание состояло в том, чтобы выбрать все варианты ответа, чтобы исключить случаи с несколькими верными ответами. Вместе с валидацией вопросов и ответов разметчики обрезали аудио до фрагмента длительностью от 5 до 20 секунд. В случае, если аудио невозможно было обрезать так, чтобы вопрос оставался релевантен – вопрос и аудио исключались.\n\nДля получения агрегированного ответа выбор каждого варианта ответа был агрегирован по методу Дэвида-Скина (каждый вариант — как независимая переменная), после чего были оставлены только вопросы с единственным выбранным вариантом ответа. В дальнейшем были использованы только те ответы разметчиков, которые совпали с агрегированным (псевдоэталонным) ответом. Аудиофрагмент в таких группах был выбран по принципу наибольшей длительности, что не влияло на ответ, так как агрегационная группировка была сделана по вопросу и ответу.",
    "Авторы": "Ульяна Исаева",
    "Human baseline": "Для всех вопросов датасета были получены ответы разметчиков на crowd-source платформе с перекрытием 5. Агрегированным ответом считался тот, который был выбран большинством (majority vote)."
}