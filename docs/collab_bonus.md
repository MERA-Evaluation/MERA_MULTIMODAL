## Attention!

Dataset submissions for the upcoming version of the MERA Multi benchmark close on September 1, 2025. We will continue to welcome contributions after that date for subsequent versions; these will not be included in the upcoming release or its accompanying paper.

## Распределение баллов за вклад в MERA

Баллы за вклад в проект MERA выдаются:
- контрибьюторам в кодовую базу (фичи, багфиксы);
- авторам, разработавшим новый датасет для MERA;
- за участие в написании академических статей;
- за проверку новых датасетов и код-ревью;
- за организационную работу.

По набранным баллам за коллаборацию участникам будет предложено соавторство в академической статье уровня A* / Q1 по мультимодальной части проекта MERA.


Общие правила:
- Чтобы стать соавтором, участнику необходимо набрать **не менее 15 баллов**. Положение соавторов в списке авторов определяется в порядке убывания баллов.
- Если вклад командный (например, датасет разрабатывают несколько человек), то **баллы выдаются на всю команду, не умножаясь**. Внутри командного вклада участники сами распределяют баллы между собой, а соавторство индивидуальное.
- Для начисления баллов нужно [положить дополнительный файл в pull request](#начисление-баллов) с вашим вкладом в MERA (как правило, в конце всех доработок, после обсуждения с reviewer).


<table>
    <thead>
        <tr>
            <th>Тип вклада</th>
            <th>Очки</th>
            <th>Definition of DONE</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Новый публичный датасет (открытая задача), соответствующий <a href="./dataset_criteria.md">требованиям</a></td>
            <td>6</td>
            <td rowspan=2>Разработана методология датасета/задачи, собраны данные, написана документация. Датасет преобразован в <a href="./dataset_formatting.md">заданный формат</a> и корректно корректно <a href="./dataset_hf.md">загружен на Hugging Face Hub</a>. Датасет финально доработан по результатам методологического ревью.</td>
        </tr>
        <tr>
            <td>Новый приватный датасет (задача рейтинга), соответствующий <a href="./dataset_criteria.md">требованиям</a></td>
            <td>9</td>
        </tr>
        <tr>
            <td>Бонусные баллы за датасет</td>
            <td>4</td>
            <td>Бонусные баллы: первый датасет, покрывающий определенный навык моделей из <a href="./skills_tax.md">карты навыков</a> (определяется в момент готовности к назначению очков; баллы за весь датасет, не за каждый навык).
            </td>
        </tr>
        <tr>
            <td>Human Baseline</td>
            <td>5</td>
            <td>Проведен <a href="./human_baseline.md">замер human baseline</a> для датасета, опубликованы ответы и скрипт для агрегации, описана методология замера.</td>
        </tr>
        <tr>
            <td>Новая задача (код)</td>
            <td>2</td>
            <td><a href="./task_code.md">Подготовлен код и yaml-таска</a> в полном комплекте с соответствием требованиям по авто-тестам.</td>
        </tr>
        <tr>
            <td>Оценка моделей-бейзлайнов на новых задачах</td>
            <td>2</td>
            <td>Проведена оценка моделей из списка бейзлайнов актуальных бейзлайнов на дату pull-request, получены скоры для нового датасета.</td>
        </tr>
        <tr>
            <td>Minor fixes</td>
            <td>1</td>
            <td>Найдены и исправлены мелкие недостатки и опечатки в описаниях датасетов, документации проекта.</td>
        </tr>
        <tr>
            <td>Major fixes (включая доработку кода)</td>
            <td>1-10</td>
            <td>Внесены изменения в кодовую базу проекта. Все авто-тесты проходят корректно, стабильность предыдущей функциональности сохранена. Закрыт issue по задаче (если применимо). Итоговое количество баллов описано при заведении issue, в отдельных случаях может быть скорректировано организаторами.</td>
        </tr>
        <tr>
            <td>Добавление API и поддержка новых моделей</td>
            <td>2</td>
            <td>В коде добавлена поддержка новой модели и/или API.</td>
        </tr>
        <tr>
            <td>Методологическое ревью</td>
            <td>2</td>
            <td>Проведена методологическая проверка датасета на соответствие <a href="./dataset_criteria.md">критериям</a>.</td>
        </tr>
        <tr>
            <td>Код-ревью</td>
            <td>2</td>
            <td>Проведено код-ревью, по результатам которого PR полностью готов к мержу или финально отклонен. Код-ревью по замороженным изменениям (не влитым в проект) не засчитывается.</td>
        </tr>
        <tr>
            <td>Статья</td>
            <td>TBA</td>
            <td>Написание статьи.</td>
        </tr>
        <tr>
            <td>Организационная работа</td>
            <td>1-5</td>
            <td>Организована часть процессов по межкомандному взаимодействию и/или менеджменту датасетов и/или написана инструкция по процессам.</td>
        </tr>
        <tr>
            <td>Прочее</td>
            <td>1+</td>
            <td>Сюда попадает всё, что не покрывается пунктами выше, но заслуживает баллов. Если участник внес свой вклад, не попадающий под блоки выше, он делает запрос на баллы (<a href="#начисление-баллов">pull-request</a>) и пишет обоснование. Ревьюеры, присваивающие баллы, смотрят и экспертно одобряют/отклоняют баллы.</td>
        </tr>
    </tbody>
</table>


### Начисление баллов

Для начисления баллов оформите pull-request в [официальный репозиторий MERA](https://github.com/MERA-Evaluation/multimodal-harness).
Чтобы добавить баллы, вам нужно добавить jsonl-файл в папку `points` (в корне проекта). Пример выглядит следующим образом:
```json
{"GitHub": "GitHubUser1", "New dataset": 4, "Dataset review": 2, "Coordination": 5}
{"GitHub": "GitHubUser2", "New dataset": 6, "Dataset review": 2}
{"GitHub": "GitHubUser3", "Review PR": 2}
```

Файл должен быть назван по номеру pull-request. Например, 142.jsonl, где 142 — номер pull-request.

Возможные ключи для включения:
```json
{
    "GitHub": "GitHubUser1",
    "New dataset": 8-14,  # Новый датасет, соответствующий требованиям
    "Human Baseline": 5,  # Проведен замер Human Baseline
    "New task": 2,  # Подготовлен код и yaml-таска в полном комплекте с соответствием требованиям по авто-тестам.
    "Running Models": 2,  # Проведена оценка моделей из списка бейзлайнов
    "Dataset annotations": 1,  # Minor fixes, найдены и исправлены мелкие недостатки и опечатки в описаниях датасетов, документации проекта.
    "Bug fixes": 1-10,  # Major fixes (включая доработку кода)
    "Model support": 2,  # В коде добавлена поддержка новой модели и/или API
    "Dataset review": 2,  # Проведена методологическая проверка датасета на соответствие критериям
    "Review PR": 2,  # Проведено код-ревью, по результатам которого PR полностью готов к мержу или финально отклонен. 
    "Paper Writing": NA,  # Написание статьи
    "Coordination": 1-5,  # Организована часть процессов
    "Other": 1+  # Прочее
}
```
